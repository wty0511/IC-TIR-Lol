{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Aux_RecAttModel_Multitask_Aug_Data_Villa_Cattan_RECSYS_champ_type.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wty0511/IC-TIR-Lol/blob/master/model_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoLSVVIBCwLm"
      },
      "source": [
        "# Interpretable Contextual Team-aware Item Recommendation: Application in Multiplayer Online Battle Arena Games\n",
        "*Andres Villa, Vladimir Araujo, Francisca Cattan*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8_YV_PIDR97"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook contains the code of the proposed model. It is composed of 8 main stages:\n",
        "\n",
        "1. Connect to gDrive\n",
        "2. Dataset and Transformations\n",
        "3. Model\n",
        "4. Logger and Checkpointer\n",
        "5. Metrics\n",
        "6. Training and evaluation loop\n",
        "7. Config file\n",
        "8. Training and evaluation executor\n",
        "9. Obtain the role and id of each champion in each match\n",
        "10. Load the attention weights\n",
        "11. Draw the attention map\n",
        "\n",
        "*This notebook can be run in it's entirety. The final cell executes the training and validation of the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYxhCKYPbBT2",
        "colab_type": "toc"
      },
      "source": [
        ">[Main Model - Project Title](#scrollTo=uoLSVVIBCwLm)\n",
        "\n",
        ">[Introduction](#scrollTo=t8_YV_PIDR97)\n",
        "\n",
        ">[Install all the dependencies](#scrollTo=etkQTYydGkFM)\n",
        "\n",
        ">[Import the dependencies](#scrollTo=S0YvGjijGxET)\n",
        "\n",
        ">[Connect to gDrive](#scrollTo=pfDyM4E7G4L2)\n",
        "\n",
        ">[Dataset and Transformations](#scrollTo=h9MDWroJSkhM)\n",
        "\n",
        ">[Model](#scrollTo=UIm1_KUCUNB0)\n",
        "\n",
        ">>[Transformer encoder modified to obtain the attention weights](#scrollTo=qr3TZbrnUg2H)\n",
        "\n",
        ">>[Auxiliary Task Classes](#scrollTo=pwRy106QU6sH)\n",
        "\n",
        ">>[Main Class of the proposed model](#scrollTo=9AlU_u42VG8A)\n",
        "\n",
        ">[Logger and Checkpointer](#scrollTo=rwYoKWcsVqex)\n",
        "\n",
        ">[Metrics](#scrollTo=5ktMqAUMWeEz)\n",
        "\n",
        ">[Training and evaluation loop](#scrollTo=WDA0GHysW4vX)\n",
        "\n",
        ">[Config file](#scrollTo=CyRfaqN8XvYi)\n",
        "\n",
        ">[Training and evaluation executor](#scrollTo=IVtKoVTcYDS1)\n",
        "\n",
        ">[T-test](#scrollTo=D2TPs5U3vv7m)\n",
        "\n",
        ">[Obtain the role and id of each champion in each match](#scrollTo=sFtaUCU5T8fl)\n",
        "\n",
        ">[Load the attention weights](#scrollTo=VINfHm76U1vz)\n",
        "\n",
        ">[Draw the attention map](#scrollTo=SvhQCEzcU6x_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etkQTYydGkFM"
      },
      "source": [
        "# Install all the dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH0huCgYRJou"
      },
      "source": [
        "Install all the libraries neccesary to run the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqG6vM9tqER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e74c20-a8ac-45bf-b821-3aaebc9a4d8c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTd06UwscDsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf25420d-881d-48fa-ad96-fa8a444e0db3"
      },
      "source": [
        "!pip install git+git://github.com/williamFalcon/pytorch-lightning.git@master --upgrade\n",
        "#!pip install pytorch-lightning==0.8.5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/williamFalcon/pytorch-lightning.git@master\n",
            "  Cloning git://github.com/williamFalcon/pytorch-lightning.git (to revision master) to /tmp/pip-req-build-selkn45g\n",
            "  Running command git clone -q git://github.com/williamFalcon/pytorch-lightning.git /tmp/pip-req-build-selkn45g\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (21.3)\n",
            "Collecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (1.10.0+cu111)\n",
            "Collecting typing-extensions>=4.0.0\n",
            "  Downloading typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (4.62.3)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.6.2-py3-none-any.whl (332 kB)\n",
            "\u001b[K     |████████████████████████████████| 332 kB 58.4 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0.dev0) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.6.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.43.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0.dev0) (3.1.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 60.7 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 70.0 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0.dev0) (2.0.10)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 66.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pytorch-lightning\n",
            "  Building wheel for pytorch-lightning (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-lightning: filename=pytorch_lightning-1.6.0.dev0-py3-none-any.whl size=540469 sha256=6861c6988fcde7424e6115783e594f7458b9b3f921a49cbf91dbae903b090a84\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n4u5_bnc/wheels/6b/1c/bd/1c1ceb9f3e46efb73ab5a32e2e08aea3c72c35e0cac0754ff3\n",
            "Successfully built pytorch-lightning\n",
            "Installing collected packages: typing-extensions, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, pytorch-lightning\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.0.1 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2022.1.0 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.6.0.dev0 torchmetrics-0.6.2 typing-extensions-4.0.1 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwD1P0lHVaLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146a395c-34ae-4951-b51f-0baf4e04444b"
      },
      "source": [
        "!pip install comet_ml==3.0.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting comet_ml==3.0.2\n",
            "  Downloading comet_ml-3.0.2-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.55.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting wurlitzer>=1.0.2\n",
            "  Downloading wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
            "Collecting comet-git-pure>=0.19.11\n",
            "  Downloading comet_git_pure-0.19.16-py3-none-any.whl (409 kB)\n",
            "\u001b[K     |████████████████████████████████| 409 kB 50.6 MB/s \n",
            "\u001b[?25hCollecting jsonschema<3.1.0,>=2.6.0\n",
            "  Downloading jsonschema-3.0.2-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from comet_ml==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from comet_ml==3.0.2) (2.23.0)\n",
            "Collecting everett[ini]>=1.0.1\n",
            "  Downloading everett-2.0.1-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml==3.0.2) (7.352.0)\n",
            "Collecting netifaces>=0.10.7\n",
            "  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from comet-git-pure>=0.19.11->comet_ml==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.7/dist-packages (from comet-git-pure>=0.19.11->comet_ml==3.0.2) (1.24.3)\n",
            "Collecting configobj\n",
            "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml==3.0.2) (21.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml==3.0.2) (57.4.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml==3.0.2) (0.18.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml==3.0.2) (2.10)\n",
            "Building wheels for collected packages: configobj\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34547 sha256=ce8f83a7c0e356dcc64b7318f940637d71d16b06bbdd0d387da5f051f1fb2b89\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
            "Successfully built configobj\n",
            "Installing collected packages: everett, configobj, wurlitzer, websocket-client, netifaces, jsonschema, comet-git-pure, comet-ml\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.9 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed comet-git-pure-0.19.16 comet-ml-3.0.2 configobj-5.0.6 everett-2.0.1 jsonschema-3.0.2 netifaces-0.11.0 websocket-client-1.2.3 wurlitzer-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vHwQVrRWBgV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "248762fa-e8cc-44b2-91dc-762491538cd7"
      },
      "source": [
        "!pip install omegaconf"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▍                           | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 20 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 71 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 74 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (6.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=6725538c678c23f3dab86437f590a47c0b33fffc12670e4dd75d5c15e3763ae6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
            "Successfully installed antlr4-python3-runtime-4.8 omegaconf-2.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yA6EwQM6P8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c24bf9-3170-4492-e12c-829aa66daac2"
      },
      "source": [
        "!pip install adabound"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adabound\n",
            "  Downloading adabound-0.0.5-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from adabound) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabound) (4.0.1)\n",
            "Installing collected packages: adabound\n",
            "Successfully installed adabound-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMNgXeWwNx-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63e09e4-6f31-422b-b9c5-50a382ff2f7b"
      },
      "source": [
        "!pip install ml_metrics"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ml_metrics\n",
            "  Downloading ml_metrics-0.1.4.tar.gz (5.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ml_metrics) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ml_metrics) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ml_metrics) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ml_metrics) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ml_metrics) (1.15.0)\n",
            "Building wheels for collected packages: ml-metrics\n",
            "  Building wheel for ml-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-metrics: filename=ml_metrics-0.1.4-py3-none-any.whl size=7845 sha256=6ef9727855f770e4c85f353d6e87ce86c4a6b00bd7c25f726a0575e0a3b48212\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/41/5b/0c6d42b3604a5c823d8922564c4708f84962fa7f2f4facfa6d\n",
            "Successfully built ml-metrics\n",
            "Installing collected packages: ml-metrics\n",
            "Successfully installed ml-metrics-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet_ml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1crRcHMOG6l",
        "outputId": "f69626f3-2faa-431f-da56-a18e02ae58f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.11.0)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.19.16)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (3.0.2)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (3.0.2)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.23.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.15.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.2.3)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.7/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2021.10.8)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.7/dist-packages (from everett[ini]>=1.0.1->comet_ml) (5.0.6)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml) (0.18.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml) (57.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml) (21.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0YvGjijGxET"
      },
      "source": [
        "# Import the dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypMu2vhSRZD2"
      },
      "source": [
        "Import all the libraries neccesary to run the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNaJbRoaa8ZU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "060e3eb9-ac1b-4913-f6da-dae1c9e711f0"
      },
      "source": [
        "from comet_ml import Experiment as CometExperiment\n",
        "from comet_ml import ExistingExperiment as CometExistingExperiment\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf.dictconfig import DictConfig\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# from tqdm.notebook import trange, tqdm\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.utilities import rank_zero_only\n",
        "from pytorch_lightning.loggers import LightningLoggerBase\n",
        "from pytorch_lightning.loggers import CometLogger\n",
        "\n",
        "import os\n",
        "import pytorch_lightning as pl\n",
        "import pickle\n",
        "import adabound\n",
        "import ml_metrics as metrics\n",
        "import random\n",
        "import itertools\n",
        "from torchvision import transforms\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ContextualVersionConflict",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mContextualVersionConflict\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9ee9154bf4c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcomet_ml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExperiment\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mCometExperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomet_ml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExistingExperiment\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mCometExistingExperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/comet_ml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m\"Optimizer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m ]\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_comet_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mLOGGER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/comet_ml/utils.py\u001b[0m in \u001b[0;36mget_comet_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;31m# type: () -> str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"comet_ml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mDistributionNotFound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Please install comet with `pip install comet_ml`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected string, Requirement, or Distribution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;34m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mworking_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mincluded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meven\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mwere\u001b[0m \u001b[0malready\u001b[0m \u001b[0mactivated\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mworking\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \"\"\"\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0mneeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneeded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0;31m# Oops, the \"best\" so far conflicts with a dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0mdependent_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequired_by\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mVersionConflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependent_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# push the new requirements onto the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mContextualVersionConflict\u001b[0m: (jsonschema 4.3.3 (/usr/local/lib/python3.7/dist-packages), Requirement.parse('jsonschema<3.1.0,>=2.6.0'), {'comet-ml'})"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfDyM4E7G4L2"
      },
      "source": [
        "# Connect to gDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLY4l7XzReoa"
      },
      "source": [
        "Connect the notebook with the gDrive, which is essential to load and save data like dataset, checkpoints, and attention weights. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmQwtSRCbchS"
      },
      "source": [
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9MDWroJSkhM"
      },
      "source": [
        "# Dataset and Transformations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vp4e1PojfUeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIDIGrXVSzdy"
      },
      "source": [
        "This is important to load the k different partitions which are obtained using cross validation k-fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mir9w6zDzkSN"
      },
      "source": [
        "train_path = '/content/gdrive/MyDrive/train_splits.pkl'\n",
        "test_path = '/content/gdrive/MyDrive/test_splits.pkl'\n",
        "champion_path = '/content/gdrive/MyDrive/champion_types.pkl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDP51QcmNgCd"
      },
      "source": [
        "#@title Cargar listas de particiones\n",
        "with open(train_path, 'rb') as handle:\n",
        "    list_trainset = pickle.load(handle)\n",
        "\n",
        "with open(test_path, 'rb') as handle:\n",
        "    list_testset = pickle.load(handle)\n",
        "\n",
        "with open(champion_path, 'rb') as handle:\n",
        "    champion_types = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zbdC7M1S3kh"
      },
      "source": [
        "def get_partition(id_split, list_splits = list_trainset):\n",
        "    df = list_splits[id_split]\n",
        "    null_registers = df.loc[(df.item1 == 0) & (df.item2 == 0) & (df.item3 == 0) & (df.item4 == 0) & (df.item5 == 0) & (df.item6 == 0)]\n",
        "    match_to_del = list(set(null_registers['matchid']))\n",
        "    df = df[~df.matchid.isin(match_to_del)]\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK-OEg1dTYJw"
      },
      "source": [
        "These transformations rote randomly the order between the two teams, and the champions within each team."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muCDKh3n524z"
      },
      "source": [
        "class RandomSort_Team(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, square crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "    \n",
        "    def get_random_sample(self, sample):\n",
        "        x, y = sample\n",
        "\n",
        "        ids_teams_1 = [x for x in range(5)]\n",
        "        ids_teams_2 = [x for x in range(5,10)]\n",
        "\n",
        "        ids_team_t = [ids_teams_1, ids_teams_2]\n",
        "\n",
        "        ids_teams = [1, 0]\n",
        "        #ids_teams = [x for x in range(2)]\n",
        "        #random.shuffle(ids_teams)\n",
        "\n",
        "        ids_team_t = [ids_team_t[i] for i in ids_teams]\n",
        "        \n",
        "        ids_team_t = list(itertools.chain.from_iterable(ids_team_t))\n",
        "\n",
        "        x['champions'] = x['champions'][ids_team_t]\n",
        "        x['role'] = x['role'][ids_team_t]\n",
        "        x['type'] = x['type'][ids_team_t,:]\n",
        "\n",
        "        y['items'] = y['items'][ids_team_t,:]\n",
        "\n",
        "        if ids_teams == [1, 0]:\n",
        "            y['win'] = torch.tensor(1) - y['win']\n",
        "        \n",
        "        return x, y\n",
        "\n",
        "    def __call__(self, sample_list):\n",
        "        list_x_champions = []\n",
        "        list_x_role = []\n",
        "        list_x_type = []\n",
        "        list_y_items = []\n",
        "        list_y_win = []\n",
        "        x_old, y_old = sample_list\n",
        "        if isinstance(x_old, (list)) and isinstance(y_old, (list)):\n",
        "            for i in range(len(x_old)):\n",
        "                list_x_champions.append(x_old[i]['champions'])\n",
        "                list_x_role.append(x_old[i]['role'])\n",
        "                list_x_type.append(x_old[i]['type'])\n",
        "                list_y_items.append(y_old[i]['items'])\n",
        "                list_y_win.append(y_old[i]['win'])\n",
        "                sample = x_old[i], y_old[i]\n",
        "                x, y = self.get_random_sample(sample)\n",
        "                list_x_champions.append(x['champions'])\n",
        "                list_x_role.append(x['role'])\n",
        "                list_x_type.append(x['type'])\n",
        "                list_y_items.append(y['items'])\n",
        "                list_y_win.append(y['win'])\n",
        "        else:\n",
        "            list_x_champions.append(x_old['champions'])\n",
        "            list_x_role.append(x_old['role'])\n",
        "            list_x_type.append(x_old['type'])\n",
        "            list_y_items.append(y_old['items'])\n",
        "            list_y_win.append(y_old['win'])\n",
        "            sample = x_old, y_old\n",
        "            x, y = self.get_random_sample(sample)\n",
        "            list_x_champions.append(x['champions'])\n",
        "            list_x_role.append(x['role'])\n",
        "            list_x_type.append(x['type'])\n",
        "            list_y_items.append(y['items'])\n",
        "            list_y_win.append(y['win'])\n",
        "        new_x = {\n",
        "            'champions': torch.stack(list_x_champions, dim=0),\n",
        "            'role': torch.stack(list_x_role, dim=0),\n",
        "            'type': torch.stack(list_x_type, dim=0)\n",
        "        }\n",
        "        new_y = {\n",
        "            'items': torch.stack(list_y_items, dim=0),\n",
        "            'win': torch.stack(list_y_win, dim=0)\n",
        "        }\n",
        "        return new_x, new_y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozFSmovk06GG"
      },
      "source": [
        "class RandomSort_Part(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, square crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "        \n",
        "\n",
        "    def __call__(self, sample):\n",
        "\n",
        "        list_t_x = []\n",
        "        list_t_y = []\n",
        "        x, y = sample\n",
        "\n",
        "        list_t_x.append(x)\n",
        "        list_t_y.append(y)\n",
        "\n",
        "        ids_team_1 = [x for x in range(5)]\n",
        "        ids_team_2 = [x for x in range(5,10)]\n",
        "        random.shuffle(ids_team_1)\n",
        "        random.shuffle(ids_team_2)\n",
        "\n",
        "        ids_match = ids_team_1\n",
        "        ids_match.extend(ids_team_2)\n",
        "        \n",
        "        x['champions'] = x['champions'][ids_match]\n",
        "        x['role'] = x['role'][ids_match]\n",
        "        x['type'] = x['type'][ids_match,:]\n",
        "\n",
        "        y['items'] = y['items'][ids_match,:]\n",
        "\n",
        "        list_t_x.append(x)\n",
        "        list_t_y.append(y)\n",
        "\n",
        "        return list_t_x, list_t_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3KCpfKDPX3D"
      },
      "source": [
        "class LolDataset(Dataset):\n",
        "  def __init__(self, data, transform=None):\n",
        "  # cargar el dataset\n",
        "    #self.matches = self._load_matches(path)\n",
        "    self.matches = data\n",
        "    # comprobar si existe el .pkl con los diccionarios\n",
        "\n",
        "    # else:\n",
        "    # extraer info. del dataframe\n",
        "    self.champions = set(self.matches['championid'])\n",
        "    self.roles = set(self.matches['position-role'])\n",
        "    self.matches_id = list(set(self.matches['matchid']))\n",
        "    self.items = self.matches['item1']\n",
        "    self.items.append(self.matches['item2'])\n",
        "    self.items.append(self.matches['item3'])\n",
        "    self.items.append(self.matches['item4'])\n",
        "    self.items.append(self.matches['item5'])\n",
        "    self.items.append(self.matches['item6'])\n",
        "    items = set(self.items)\n",
        "    self.items = {i for i in items if i != 0}\n",
        "    self.champion_types = champion_types\n",
        "    list_champion_types = []\n",
        "    for k,v in champion_types.items():\n",
        "      list_champion_types.extend(v)\n",
        "  \n",
        "    self.set_champ_type = set(list_champion_types)\n",
        "\n",
        "    # crear diccionarios token2id y id2token\n",
        "    self.champions_token2id, self.champions_id2token = self._token_dict(self.champions)\n",
        "    self.roles_token2id, self.roles_id2token = self._token_dict(self.roles)\n",
        "    self.items_token2id, self.items_id2token = self._token_dict(self.items)\n",
        "    self.types_token2id, self.types_id2token = self._token_dict(self.set_champ_type)\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "  def _load_matches(self, path):\n",
        "    data_matches = pd.read_csv(path) \n",
        "    return data_matches\n",
        "\n",
        "  def _token_dict(self, data):\n",
        "    token2id = {}\n",
        "    id2token = {}\n",
        "    for i, j in enumerate(data):\n",
        "      token2id.update({j:i})\n",
        "      id2token.update({i:j})\n",
        "\n",
        "    return token2id, id2token\n",
        "\n",
        "  def _tokens2ids(self, token2id, tokens):\n",
        "    ids = []\n",
        "    for token in tokens:\n",
        "      ids.append(token2id[token])\n",
        "      \n",
        "    return ids\n",
        "\n",
        "  def _tokens2ids_items(self, token2id, tokens):\n",
        "    #items_vecs = []\n",
        "    item_vec = np.zeros((len(token2id)))\n",
        "    for token in tokens:\n",
        "      if token in token2id: \n",
        "        item_vec[token2id[token]] = 1\n",
        "      #items_vecs.append(item_vec)\n",
        "      \n",
        "    return item_vec\n",
        "\n",
        "  def _build_dict(self, match):\n",
        "    # sacar en orden los campeones de la partida\n",
        "    champion_tokens = list(match['championid'])\n",
        "    champions_ids = self._tokens2ids(self.champions_token2id, champion_tokens)\n",
        "\n",
        "    # sacar en orden los items de la partida\n",
        "    #items_tokens = match['championid']\n",
        "    #items_ids = self._tokens2ids(self.items_token2id, items_tokens)\n",
        "    # sacar en orden los roles de la partida\n",
        "    role_tokens = list(match['position-role'])\n",
        "    role_ids = self._tokens2ids(self.roles_token2id, role_tokens)\n",
        "    list_win = list(match['win'])[4:6]\n",
        "    \n",
        "    list_win = np.array(list_win)\n",
        "    num_win = np.argsort(list_win)\n",
        "    num_win = num_win[len(num_win)-1]\n",
        "\n",
        "    list_part_items = []\n",
        "    list_types = []\n",
        "    items_list = ['item1','item2','item3','item4','item5','item6']\n",
        "    for id_champ in champion_tokens:\n",
        "      champ_atr = match[match.championid == id_champ]\n",
        "      items = champ_atr[items_list]\n",
        "      items_tokens = list(items.iloc[0, :])\n",
        "      items_ids = self._tokens2ids_items(self.items_token2id, items_tokens)\n",
        "      list_part_items.append(items_ids)\n",
        "\n",
        "      type_champ = self.champion_types[id_champ]\n",
        "      type_ids = self._tokens2ids(self.types_token2id, type_champ)\n",
        "      list_types.append(type_ids)\n",
        "\n",
        "    # construir 5 veces 0s y 5 veces 1s\n",
        "    #team_ids = \n",
        "    x = {\n",
        "        'champions': torch.from_numpy(np.array(champions_ids)),\n",
        "        'role': torch.from_numpy(np.array(role_ids)),\n",
        "        'type': torch.from_numpy(np.array(list_types))\n",
        "    }\n",
        "    y= {\n",
        "        'items': torch.from_numpy(np.array(list_part_items)),\n",
        "        'win': torch.from_numpy(np.array(num_win))\n",
        "    }\n",
        "    \n",
        "    return x, y\n",
        "\n",
        "  def __getitem__(self, idx): \n",
        "    # idx es el match_id en este caso\n",
        "    # la función debiera retornar la info de cada partida\n",
        "    # buscar idx de la partida en mi estructura, y retornar los diccionarios con los atributos\n",
        "    id_match = self.matches_id[idx]\n",
        "    match = self.matches[(self.matches.matchid == id_match)]\n",
        "    x, y = self._build_dict(match) # entrega un df de la partida según el idx\n",
        "    if self.transform:\n",
        "        sample = x, y\n",
        "        x, y = self.transform(sample)\n",
        "    return x, y # el item per sé, la partida con todas sus características\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.matches_id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIm1_KUCUNB0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr3TZbrnUg2H"
      },
      "source": [
        "## Transformer encoder modified to obtain the attention weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQvpd9lxxQqI"
      },
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    \"\"\"TransformerEncoder is a stack of N encoder layers\n",
        "\n",
        "    Args:\n",
        "        encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
        "        num_layers: the number of sub-encoder-layers in the encoder (required).\n",
        "        norm: the layer normalization component (optional).\n",
        "\n",
        "    Examples::\n",
        "        >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "        >>> transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "        >>> src = torch.rand(10, 32, 512)\n",
        "        >>> out = transformer_encoder(src)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = _get_clones(encoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "        self.norm = norm\n",
        "\n",
        "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
        "        \"\"\"Pass the input through the endocder layers in turn.\n",
        "\n",
        "        Args:\n",
        "            src: the sequnce to the encoder (required).\n",
        "            mask: the mask for the src sequence (optional).\n",
        "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
        "\n",
        "        Shape:\n",
        "            see the docs in Transformer class.\n",
        "        \"\"\"\n",
        "        output = src\n",
        "        att_weights = []\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            output, attn_output_weights = self.layers[i](output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
        "            \n",
        "            att_weights.append(attn_output_weights)\n",
        "\n",
        "        if self.norm:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output, att_weights\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh2Nz2CWDypX"
      },
      "source": [
        "def _get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "\n",
        "def _get_activation_fn(activation):\n",
        "    if activation == \"relu\":\n",
        "        return F.relu\n",
        "    elif activation == \"gelu\":\n",
        "        return F.gelu\n",
        "    else:\n",
        "        raise RuntimeError(\"activation should be relu/gelu, not %s.\" % activation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJCX_mqojgwQ"
      },
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    \"\"\"TransformerEncoderLayer is made up of self-attn and feedforward network.\n",
        "    This standard encoder layer is based on the paper \"Attention Is All You Need\".\n",
        "    Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n",
        "    Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in\n",
        "    Neural Information Processing Systems, pages 6000-6010. Users may modify or implement\n",
        "    in a different way during application.\n",
        "\n",
        "    Args:\n",
        "        d_model: the number of expected features in the input (required).\n",
        "        nhead: the number of heads in the multiheadattention models (required).\n",
        "        dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
        "\n",
        "    Examples::\n",
        "        >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "        >>> src = torch.rand(10, 32, 512)\n",
        "        >>> out = encoder_layer(src)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = _get_activation_fn(activation)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        \"\"\"Pass the input through the endocder layer.\n",
        "\n",
        "        Args:\n",
        "            src: the sequnce to the encoder layer (required).\n",
        "            src_mask: the mask for the src sequence (optional).\n",
        "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
        "\n",
        "        Shape:\n",
        "            see the docs in Transformer class.\n",
        "        \"\"\"\n",
        "        src2, attn_output_weights = self.self_attn(src, src, src, attn_mask=src_mask,\n",
        "                              key_padding_mask=src_key_padding_mask)\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "        if hasattr(self, \"activation\"):\n",
        "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        else:  # for backward compatibility\n",
        "            src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src, attn_output_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwRy106QU6sH"
      },
      "source": [
        "## Auxiliary Task Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNyvw9ynsLq3"
      },
      "source": [
        "def getItems(gt_items, table_emb, num_items, emb_dim):\n",
        "    list_match = []\n",
        "    device = gt_items.device\n",
        "    for i in range(gt_items.size(0)):\n",
        "        match = gt_items[i,:,:]\n",
        "        list_part_item = []\n",
        "        for j in range(gt_items.size(1)):\n",
        "            participant_items = match[j,:]\n",
        "            sum_k = torch.sum(participant_items, dim = 0).item()\n",
        "            if int(sum_k) > 0:\n",
        "                _, pos_items = torch.topk(participant_items, k = int(sum_k), dim = 0)\n",
        "                items_emb = table_emb(pos_items)\n",
        "                items_emb = torch.mean(items_emb, dim = 0)\n",
        "                list_part_item.append(items_emb)\n",
        "            else:\n",
        "                list_part_item.append(torch.zeros(emb_dim).to(device))\n",
        "        team_item_emb = torch.stack(list_part_item)\n",
        "        list_match.append(team_item_emb)\n",
        "    return torch.stack(list_match)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KahjODMTdPS4"
      },
      "source": [
        "class WinEncoder(nn.Module):\n",
        "    def __init__(self, model_dim, n_items):\n",
        "        super(WinEncoder, self).__init__()\n",
        "        self.proj_win = nn.Linear(4*model_dim, 2)\n",
        "        self.embeddings_table_items = nn.Embedding(num_embeddings = n_items, embedding_dim = model_dim)\n",
        "        self.n_items = n_items\n",
        "        self.model_dim = model_dim\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.proj_win.bias.data.zero_()\n",
        "        self.proj_win.weight.data.uniform_(-initrange, initrange)\n",
        "        self.embeddings_table_items.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, att_match, item_list):\n",
        "        # att_match size (Batch, Seq, Emb)\n",
        "        # item_list size (Batch, Seq, Num_items, Emb)\n",
        "        att_item_team_1, att_item_team_2 = torch.chunk(att_match, 2, dim=1)\n",
        "        items_team_1, items_team_2 = torch.chunk(item_list, 2, dim=1)\n",
        "\n",
        "        items_team_1 = getItems(items_team_1, self.embeddings_table_items, self.n_items,self.model_dim)\n",
        "        items_team_2 = getItems(items_team_2, self.embeddings_table_items, self.n_items,self.model_dim)\n",
        "\n",
        "        att_item_team_1 = torch.mean(att_item_team_1, dim=1)\n",
        "        att_item_team_1 = F.relu(att_item_team_1)\n",
        "        att_item_team_1 = (att_item_team_1 / att_item_team_1.max())\n",
        "        items_team_1 = torch.mean(items_team_1, dim=1)\n",
        "        items_team_1 = F.relu(items_team_1)\n",
        "        items_team_1 = (items_team_1 / items_team_1.max())\n",
        "\n",
        "        att_item_team_2 = torch.mean(att_item_team_2, dim=1)\n",
        "        att_item_team_2 = F.relu(att_item_team_2)\n",
        "        att_item_team_2 = (att_item_team_2 / att_item_team_2.max())\n",
        "        items_team_2 = torch.mean(items_team_2, dim=1)\n",
        "        items_team_2 = F.relu(items_team_2)\n",
        "        items_team_2 = (items_team_2 / items_team_2.max())\n",
        "\n",
        "        att_item_team_1 = torch.cat((att_item_team_1, items_team_1), 1)\n",
        "        att_item_team_2 = torch.cat((att_item_team_2, items_team_2), 1)\n",
        "        proj_win_team = torch.cat((att_item_team_1, att_item_team_2), 1)\n",
        "        win_emb = self.proj_win(F.relu(proj_win_team))\n",
        "\n",
        "        return win_emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdzByFr9ZyB7"
      },
      "source": [
        "def getTensorPredItem(items_logits):\n",
        "  pred_items = torch.zeros(items_logits.size())\n",
        "  for i in range(items_logits.size(0)):\n",
        "    for j in range(items_logits.size(1)):\n",
        "      _,pos_items = torch.topk(items_logits[i,j,:],k = 6,dim=0)\n",
        "      pred_items[i,j,pos_items] = 1\n",
        "  return pred_items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AlU_u42VG8A"
      },
      "source": [
        "## Main Class of the proposed model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY-TRDX2BHAr"
      },
      "source": [
        "class TransformerLolRecommender(nn.Module):\n",
        "\n",
        "    def __init__(self, n_role, n_champions, embeddings_size, nhead, n_items, n_type, nlayers = 1, nhid = 2048, dropout=0.5, aux_task = False, \n",
        "                 learnable_team_emb = False):\n",
        "        super(TransformerLolRecommender, self).__init__()\n",
        "\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "        \n",
        "        self.embeddings_table_role = nn.Embedding(num_embeddings = n_role, embedding_dim = embeddings_size)\n",
        "        \n",
        "        self.embeddings_table_champion = nn.Embedding(num_embeddings = n_champions, embedding_dim = embeddings_size)\n",
        "\n",
        "        self.embeddings_table_type = nn.Embedding(num_embeddings = n_type, embedding_dim = embeddings_size, padding_idx=0)\n",
        "        \n",
        "        self.learnable_team_emb = learnable_team_emb\n",
        "        if learnable_team_emb:\n",
        "            self.team_encoder = nn.Embedding(num_embeddings = 2, embedding_dim = embeddings_size)\n",
        "        else:\n",
        "            self.team_encoder = self.get_team_encoding(embeddings_size, 10)\n",
        "        \n",
        "        encoder_layers = TransformerEncoderLayer(embeddings_size, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        \n",
        "        self.recommender = nn.Linear(embeddings_size, n_items)\n",
        "        self.pred_champ = nn.Linear(embeddings_size, n_champions)\n",
        "\n",
        "        self.aux_task = aux_task\n",
        "\n",
        "        if self.aux_task: \n",
        "            self.win_encoder = WinEncoder(embeddings_size, n_items)\n",
        "\n",
        "        self.init_weights()\n",
        "    \n",
        "    def get_learnable_team_emb(self, num_batch):\n",
        "        emb_team_0 = self.team_encoder(torch.LongTensor([0]).to(self.device))\n",
        "        emb_team_0 = emb_team_0.expand(5, emb_team_0.size(1))\n",
        "        emb_team_1 = self.team_encoder(torch.LongTensor([1]).to(self.device))\n",
        "        emb_team_1 = emb_team_1.expand(5, emb_team_1.size(1))\n",
        "        emb_team = torch.cat([emb_team_0, emb_team_1], dim = 0)\n",
        "        emb_team = emb_team.unsqueeze(0).expand(num_batch, emb_team.size(0), emb_team.size(1))\n",
        "        return emb_team\n",
        "\n",
        "    \n",
        "    def get_team_encoding(self, embedding_dim, num_champions = 10):\n",
        "        team_encoding = torch.zeros(num_champions, embedding_dim)\n",
        "        team_encoding[5:,:] = 1\n",
        "        return team_encoding.to(self.device)\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        \n",
        "        self.embeddings_table_role.weight.data.uniform_(-initrange, initrange)\n",
        "        self.embeddings_table_champion.weight.data.uniform_(-initrange, initrange)\n",
        "        self.embeddings_table_type.weight.data.uniform_(-initrange, initrange)\n",
        "        \n",
        "        self.recommender.bias.data.zero_()\n",
        "        self.recommender.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "        self.pred_champ.bias.data.zero_()\n",
        "        self.pred_champ.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "        if self.learnable_team_emb:\n",
        "            self.team_encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, role, champion_id, types, items, win, enable_teacher_f):\n",
        "\n",
        "        role_participants = self.embeddings_table_role(role)\n",
        "        id_participants = self.embeddings_table_champion(champion_id)\n",
        "        type_champ = self.embeddings_table_type(types)\n",
        "        type_champ = torch.sum(type_champ, dim =2)\n",
        "        batch_size = role_participants.size(0)\n",
        "        if self.learnable_team_emb:\n",
        "            team_participants = self.get_learnable_team_emb(batch_size)\n",
        "        else:\n",
        "            size_team_emb = self.team_encoder.size()\n",
        "            team_participants = self.team_encoder.unsqueeze(0).expand(batch_size, size_team_emb[0], size_team_emb[1])\n",
        "\n",
        "        sel_champions = []\n",
        "        pos_champions = []\n",
        "        for i in range(win.size(0)):\n",
        "            id_el = random.randint(0,4)\n",
        "            pos_champions.append(id_el)\n",
        "            if win[i] != 0:\n",
        "                id_el = id_el + 5\n",
        "            sel_champion = champion_id[i,id_el]\n",
        "            id_participants[i,id_el,:] = 0\n",
        "            sel_champions.append(sel_champion)\n",
        "\n",
        "        sel_champions = torch.stack(sel_champions)\n",
        "        # pos_champions = torch.stack(pos_champions)\n",
        "\n",
        "        participants = role_participants + id_participants + team_participants + type_champ\n",
        "        # size (Seq, Batch, Emb)\n",
        "        participants = participants.permute(1,0,2)\n",
        "        # size (Seq, Batch, Emb)\n",
        "        output, att_weights = self.transformer_encoder(participants)\n",
        "        # size (Batch, Seq, Emb)\n",
        "        output = output.permute(1,0,2)\n",
        "        logits_items = self.recommender(output)\n",
        "\n",
        "        output_obj = {\n",
        "            'logits_items': logits_items,\n",
        "            'att_weights': att_weights,\n",
        "            'outputs': output,\n",
        "            'sel_champions': sel_champions,\n",
        "            'pos_champions': pos_champions\n",
        "        }\n",
        "\n",
        "        if self.aux_task:\n",
        "            if enable_teacher_f: \n",
        "                items_used = items\n",
        "            else:\n",
        "                items_used = getTensorPredItem(logits_items).to(self.device)\n",
        "            logits_win = self.win_encoder(output, items_used)\n",
        "            output_obj['logits_win'] = logits_win\n",
        "\n",
        "        return output_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwYoKWcsVqex"
      },
      "source": [
        "# Logger and Checkpointer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrXJc5reVwyM"
      },
      "source": [
        "These classes and methods are essential to log relevant information about the model and metrics in Coment. Likewise, they allow to save checkpoint in each epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0JLqdBEV67X"
      },
      "source": [
        "def load_defaults(defaults_file):\n",
        "    return OmegaConf.load(defaults_file)\n",
        "\n",
        "\n",
        "def load_config_file(config_file):\n",
        "    if not config_file:\n",
        "        return OmegaConf.create()\n",
        "    return OmegaConf.load(config_file)\n",
        "\n",
        "\n",
        "def load_config(config_file, defaults_file):\n",
        "    defaults = load_defaults(defaults_file)\n",
        "    config = OmegaConf.merge(defaults, load_config_file(config_file))\n",
        "    config.merge_with_cli()\n",
        "    return config\n",
        "\n",
        "\n",
        "def build_config(args):\n",
        "    return load_config(args.config_file, args.defaults_file)\n",
        "\n",
        "\n",
        "def config_to_dict(cfg):\n",
        "    return dict(cfg)\n",
        "\n",
        "\n",
        "def config_to_comet(cfg):\n",
        "    def _config_to_comet(cfg, local_dict, parent_str):\n",
        "        for key, value in cfg.items():\n",
        "            full_key = \"{}.{}\".format(parent_str, key)\n",
        "            if isinstance(value, (dict, DictConfig)):\n",
        "                _config_to_comet(value, local_dict, full_key)\n",
        "            else:\n",
        "                local_dict[full_key] = value\n",
        "\n",
        "    local_dict = {}\n",
        "    for key, value in cfg.items():\n",
        "        if isinstance(value, (dict, DictConfig)):\n",
        "            _config_to_comet(value, local_dict, key)\n",
        "        else:\n",
        "            local_dict[key] = value\n",
        "    return local_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWTpFcpaU50q"
      },
      "source": [
        "def get_checkpointer(save_path, metric_name='val_acc'):\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    return ModelCheckpoint(\n",
        "        filepath=save_path,\n",
        "        verbose=True,\n",
        "        monitor=metric_name,\n",
        "        mode='max',\n",
        "    )\n",
        "\n",
        "\n",
        "# class CometLogger(LightningLoggerBase):\n",
        "#     # Thank you @ceyzaguirre4\n",
        "#     def __init__(self, config, *args, **kwargs):\n",
        "#         super().__init__()\n",
        "#         self.comet_exp = CometExperiment(*args, **kwargs)\n",
        "#         self.comet_exp.set_name(config['exp_name'])\n",
        "#         self.comet_exp.log_parameters(config)\n",
        "#         self.config = config\n",
        "\n",
        "#     @rank_zero_only\n",
        "#     def log_hyperparams(self, params):\n",
        "#         self.comet_exp.log_parameters(config_to_comet(params))\n",
        "\n",
        "#     @rank_zero_only\n",
        "#     def log_metrics(self, metrics, step):\n",
        "#         self.comet_exp.log_metrics(metrics)\n",
        "\n",
        "#     @rank_zero_only\n",
        "#     def finalize(self, status):\n",
        "#         self.comet_exp.end()\n",
        "    \n",
        "#     def version(self):\n",
        "#         return self.config['exp']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ktMqAUMWeEz"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TMnKThtdtb4"
      },
      "source": [
        "def recall_at_k(output, target, k = 6):\n",
        "    output_k, ind_k = torch.topk(output, k, dim = 1)\n",
        "    sum_recall = 0\n",
        "    num_part = output_k.size(0)\n",
        "    relevants = target.sum(dim = 1)\n",
        "    list_recall = []\n",
        "    for i in range(num_part):\n",
        "      target_k = target[i, ind_k[i,:]]\n",
        "      intersection = target_k.sum(dim = 0)\n",
        "      recall_n = intersection/relevants[i]\n",
        "      list_recall.append(recall_n)\n",
        "      sum_recall+=recall_n\n",
        "    \n",
        "    recall_avg = sum_recall/num_part\n",
        "    return recall_avg, num_part, list_recall\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xRNZaAJ_RZ8"
      },
      "source": [
        "def precision_at_k(r, k):\n",
        "    \"\"\"Score is precision @ k\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> r = [0, 0, 1]\n",
        "    >>> precision_at_k(r, 1)\n",
        "    0.0\n",
        "    >>> precision_at_k(r, 2)\n",
        "    0.0\n",
        "    >>> precision_at_k(r, 3)\n",
        "    0.33333333333333331\n",
        "    >>> precision_at_k(r, 4)\n",
        "    Traceback (most recent call last):\n",
        "        File \"<stdin>\", line 1, in ?\n",
        "    ValueError: Relevance score length < k\n",
        "\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Precision @ k\n",
        "\n",
        "    Raises:\n",
        "        ValueError: len(r) must be >= k\n",
        "    \"\"\"\n",
        "    assert k >= 1\n",
        "    r = np.asarray(r)[:k] != 0\n",
        "    if r.size != k:\n",
        "        raise ValueError('Relevance score length < k')\n",
        "    return np.mean(r)\n",
        "\n",
        "\n",
        "def average_precision(r):\n",
        "    \"\"\"Score is average precision (area under PR curve)\n",
        "\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "\n",
        "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
        "    >>> delta_r = 1. / sum(r)\n",
        "    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
        "    0.7833333333333333\n",
        "    >>> average_precision(r)\n",
        "    0.78333333333333333\n",
        "\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "\n",
        "    Returns:\n",
        "        Average precision\n",
        "    \"\"\"\n",
        "    r = np.asarray(r) != 0\n",
        "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
        "    if not out:\n",
        "        return 0.\n",
        "    return np.mean(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfusZ9qS_uSq"
      },
      "source": [
        "def map_at(output, target, k=6):\n",
        "    sum_ap = 0\n",
        "    num_part = output.size(0)\n",
        "    list_map = []\n",
        "    for i in range(num_part):\n",
        "      out_p = output[i,:]\n",
        "      target_p = target[i,:]\n",
        "      output_k, ind_k = torch.topk(out_p, k, dim = 0)\n",
        "      list_rel = target_p[ind_k].tolist()\n",
        "      ap_at = average_precision(list_rel)\n",
        "      list_map.append(ap_at) \n",
        "      sum_ap += ap_at\n",
        "    return sum_ap/num_part, list_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CctZXsremks4"
      },
      "source": [
        "def calc_precision_multiclass(output, target, k = 6):\n",
        "    output_k, ind_k = torch.topk(output, k, dim = 1)\n",
        "    sum_prec = 0\n",
        "    num_part = output_k.size(0)\n",
        "    list_prec = []\n",
        "    for i in range(num_part):\n",
        "      target_k = target[i, ind_k[i,:]]\n",
        "      intersection = target_k.sum(dim = 0)\n",
        "      preci_n = intersection/k\n",
        "      list_prec.append(preci_n)\n",
        "      sum_prec+=preci_n\n",
        "    \n",
        "    prec_avg = sum_prec/num_part\n",
        "    return prec_avg, num_part, list_prec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mykasAMS0bnG"
      },
      "source": [
        "def f1_score(recall, precision):\n",
        "  f1 = 2 * ((precision * recall) / (precision + recall))\n",
        "  return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zMdgUJslL4V"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\n",
        "    Taken from PyTorch's examples.imagenet.main\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x01LspaO_A7f"
      },
      "source": [
        "def set_seed(seed, slow=False):\n",
        "    import random\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    if slow:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2URNBE4I7x7j"
      },
      "source": [
        "def get_winners(att_vec, gt_item, win_vec, pos_champions, outputs_log):\n",
        "    list_att = []\n",
        "    list_gt = []\n",
        "    list_cham = []\n",
        "    for i in range(att_vec.size(0)):\n",
        "        win = win_vec[i]\n",
        "        pos = pos_champions[i]\n",
        "        if win == 0:\n",
        "            a = list(range(0,5))\n",
        "            del a[pos]\n",
        "            att_vec_match = att_vec[i,a,:]\n",
        "            gt_match = gt_item[i,a, :]\n",
        "            list_cham.append(outputs_log[i,pos, :])\n",
        "            list_att.append(att_vec_match)\n",
        "            list_gt.append(gt_match)          \n",
        "        else:\n",
        "            a = list(range(5,10))\n",
        "            del a[pos]\n",
        "            att_vec_match = att_vec[i,a,:]\n",
        "            gt_match = gt_item[i, a, :]\n",
        "            list_cham.append(outputs_log[i,pos + 5, :])\n",
        "            list_att.append(att_vec_match)\n",
        "            list_gt.append(gt_match)\n",
        "\n",
        "    att_winners = torch.stack(list_att, dim=0)\n",
        "    gt_winners = torch.stack(list_gt, dim=0)\n",
        "    att_cham = torch.stack(list_cham, dim=0)\n",
        "    return att_winners, gt_winners, att_cham\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3xn5Zd30i3C"
      },
      "source": [
        "def save_att_weights(list_att, path_save_att):\n",
        "  with open(path_save_att, 'wb') as handle:\n",
        "    pickle.dump(list_att, handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDA0GHysW4vX"
      },
      "source": [
        "# Training and evaluation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVeG7SOJW80S"
      },
      "source": [
        "The training and evaluation loop are based on [Pytorch-lightning](https://github.com/williamFalcon/pytorch-lightning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOJROUqzSqJU"
      },
      "source": [
        "import argparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR77pKXdXDDF"
      },
      "source": [
        "class Struct:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "        #self.elems = entries.items()\n",
        "    \n",
        "    def items(self):\n",
        "        return self.__dict__.items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxtiaNMYc6iw"
      },
      "source": [
        "class LolRecAttModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super(LolRecAttModel, self).__init__()\n",
        "        \n",
        "        if type(cfg) is argparse.Namespace:\n",
        "          cfg = vars(cfg)\n",
        "        self.conf = cfg\n",
        "        self.hparams = cfg\n",
        "        self.index_split = self.conf['index_split']\n",
        "        self.optim = self.conf['optim']\n",
        "        set_seed(seed = self.conf['seed'])\n",
        "        train_dataset = self.train_dataset()\n",
        "        self.batch_size = self.conf['batch_size']\n",
        "        self.iter_max_train = len(train_dataset)//self.batch_size\n",
        "        num_roles = len(train_dataset.roles)\n",
        "        num_champions = len(train_dataset.champions)\n",
        "        n_items = len(train_dataset.items)\n",
        "        n_types = len(train_dataset.set_champ_type)\n",
        "        self.model = TransformerLolRecommender(n_role=num_roles, n_champions=num_champions, embeddings_size=self.conf['embeddings_size'], nhead=self.conf['nhead'], n_items=n_items, n_type=n_types,\n",
        "                                               nlayers = self.conf['nlayers'], nhid = self.conf['nhid'], dropout=self.conf['dropout'], aux_task = self.conf['win_task'], \n",
        "                                               learnable_team_emb = self.conf['learnable_team_emb'])\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "        self.loss_aux = nn.CrossEntropyLoss()\n",
        "        self.train_loss = AverageMeter()\n",
        "        self.train_prec = AverageMeter()\n",
        "        self.iter_epoch = 0\n",
        "        isExist = os.path.exists(path_save) \n",
        "        if isExist:\n",
        "          dirs = os.listdir(path_save)\n",
        "          self.iter_epoch = len(dirs)\n",
        "\n",
        "        self.aux_task = self.conf['win_task']\n",
        "        \n",
        "        if self.aux_task:\n",
        "            self.second_loss = nn.CrossEntropyLoss()\n",
        "            self.train_acc_win = AverageMeter()\n",
        "            self.train_main_loss = AverageMeter()\n",
        "            self.train_win_loss = AverageMeter()\n",
        "            self.alpha = self.conf['alpha']\n",
        "            self.beta = self.conf['beta']\n",
        "            self.epoch_to_win = self.conf['init_epoch']\n",
        "\n",
        "    def check_epoch(self, num_iter):\n",
        "      if num_iter == 0:\n",
        "        self.train_loss = AverageMeter()\n",
        "        self.train_prec = AverageMeter()\n",
        "        if self.aux_task:\n",
        "            self.train_acc_win = AverageMeter()\n",
        "            self.train_main_loss = AverageMeter()\n",
        "            self.train_win_loss = AverageMeter()\n",
        "        self.iter_epoch+=1\n",
        "\n",
        "    def custom_print(self, batch,  loss, start_time, prec, acc = 0, log_interval = 100, loss_win =0, epoch=1):\n",
        "      if batch % log_interval == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            elapsed = elapsed*log_interval if batch > 0 else elapsed\n",
        "            if self.aux_task and self.iter_epoch >= self.epoch_to_win:\n",
        "                print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                      'ms/batch {:5.2f} | '\n",
        "                      'loss {:5.6f} | loss win {:5.6f} | precision {:5.6f} | Accuracy (win) {:5.6f}'.format(\n",
        "                        self.iter_epoch, batch, self.iter_max_train,\n",
        "                        elapsed, loss, loss_win, prec, acc))\n",
        "            else:\n",
        "                print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                      'ms/batch {:5.2f} | '\n",
        "                      'loss {:5.6f} | precision {:5.6f}'.format(\n",
        "                        self.iter_epoch, batch, self.iter_max_train,\n",
        "                        elapsed, loss, prec)) \n",
        "\n",
        "    def forward(self, x, items, win, teacher_forcing):\n",
        "        role = x['role']\n",
        "        champions = x['champions']\n",
        "        types = x['type']\n",
        "        out = self.model(role, champions, types, items, win, teacher_forcing)\n",
        "        return out\n",
        "        #return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        # REQUIRED\n",
        "        self.check_epoch(batch_nb)\n",
        "        start_time = time.time()\n",
        "        x, y = batch\n",
        "        if len(x['role'].size()) == 3:\n",
        "          x['role'] = x['role'].reshape(x['role'].size(0)*x['role'].size(1), x['role'].size(2))\n",
        "          x['champions'] = x['champions'].reshape(x['champions'].size(0)*x['champions'].size(1), x['champions'].size(2))\n",
        "          x['type'] = x['type'].reshape(x['type'].size(0)*x['type'].size(1), x['type'].size(2), x['type'].size(3))\n",
        "          y['items'] = y['items'].reshape(y['items'].size(0)*y['items'].size(1), y['items'].size(2), y['items'].size(3))\n",
        "          y['win'] = y['win'].reshape(y['win'].size(0)*y['win'].size(1))\n",
        "        y_hat = self.forward(x, y['items'], y['win'], self.conf['teacher_forcing'])\n",
        "        \n",
        "        #Mains task\n",
        "        logits_items = y_hat['logits_items']\n",
        "        gt_items = y['items']\n",
        "        sel_champions = y_hat['sel_champions']\n",
        "        pos_champions = y_hat['pos_champions']\n",
        "        outputs_log = y_hat['outputs']\n",
        "        logits_items, gt_items, att_cham = get_winners(logits_items, gt_items, y['win'], pos_champions, outputs_log)\n",
        "        \n",
        "        out = logits_items.reshape(logits_items.size(0)*logits_items.size(1), logits_items.size(2))\n",
        "        out_aux = self.model.pred_champ(att_cham)\n",
        "\n",
        "        gt = gt_items.reshape(gt_items.size(0)*gt_items.size(1), gt_items.size(2))\n",
        "        loss = self.loss(out, gt)\n",
        "        loss_aux = self.loss_aux(out_aux, sel_champions)\n",
        "\n",
        "        prec, num, _ = calc_precision_multiclass(out, gt, k=6)\n",
        "        self.train_prec.update(prec, num)\n",
        "\n",
        "        tensor_avg_prec = torch.tensor([self.train_prec.avg], device=loss.device)\n",
        "        tensorboard_logs = {'train_loss': loss, 'train_loss_aux': loss_aux, 'train_prec_avg': tensor_avg_prec}\n",
        "\n",
        "        if self.aux_task and self.iter_epoch >= self.epoch_to_win:\n",
        "\n",
        "            #Second Task\n",
        "            out_win = y_hat['logits_win']\n",
        "            \n",
        "            gt_win = y['win'].reshape(-1)\n",
        "\n",
        "            _, preds_win = torch.max(out_win, 1)\n",
        "\n",
        "            loss_win = self.second_loss(out_win, gt_win)\n",
        "            loss_total = self.alpha*loss + self.beta*loss_win\n",
        "            self.train_loss.update(self.alpha*loss.item(), out.size(0))\n",
        "            self.train_loss.update(self.beta*loss_win.item(), out_win.size(0))\n",
        "\n",
        "            train_acc = torch.sum(preds_win == gt_win).item()/out_win.size(0)\n",
        "            self.train_acc_win.update(train_acc, out_win.size(0))\n",
        "            self.train_main_loss.update(loss.item(), out.size(0))\n",
        "            self.train_win_loss.update(loss_win.item(), out_win.size(0))\n",
        "\n",
        "            tensor_avg_acc = torch.tensor([self.train_acc_win.avg], device=loss.device)\n",
        "            tensorboard_logs['train_acc_win_avg'] = tensor_avg_acc\n",
        "            tensorboard_logs['train_win_loss'] = loss_win\n",
        "            tensorboard_logs['train_main_loss'] = loss\n",
        "            tensorboard_logs['train_win_loss_avg'] = torch.tensor([self.train_win_loss.avg], device=loss.device)\n",
        "            tensorboard_logs['train_main_loss_avg'] = torch.tensor([self.train_main_loss.avg], device=loss.device)\n",
        "            tensorboard_logs['train_loss'] = loss_total\n",
        "\n",
        "            # self.custom_print(batch_nb, self.train_main_loss.avg, start_time, self.train_prec.avg, self.train_acc_win.avg, 100, self.train_win_loss.avg)\n",
        "        else:\n",
        "            loss_total = loss + 0.2*loss_aux\n",
        "            self.train_loss.update(loss.item(), out.size(0))\n",
        "            tensorboard_logs['total_loss_train'] = loss_total\n",
        "            # self.custom_print(batch_nb, self.train_loss.avg, start_time, self.train_prec.avg, 0, 100)\n",
        "        \n",
        "        tensor_avg_loss = torch.tensor([self.train_loss.avg], device=loss.device)\n",
        "        tensorboard_logs['train_loss_avg'] = tensor_avg_loss\n",
        "        return {'loss': loss_total, 'progress_bar': tensorboard_logs, 'avg_loss':  tensor_avg_loss, 'avg_prec':tensor_avg_prec ,'log': tensorboard_logs}\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x, y['items'], y['win'], False)\n",
        "        att_weights = y_hat['att_weights']\n",
        "\n",
        "        #Main Task\n",
        "        logits_items = y_hat['logits_items']\n",
        "        gt_items = y['items']\n",
        "        sel_champions = y_hat['sel_champions']\n",
        "        pos_champions = y_hat['pos_champions']\n",
        "        outputs_log = y_hat['outputs']\n",
        "\n",
        "        logits_items, gt_items, att_cham = get_winners(logits_items, gt_items, y['win'], pos_champions, outputs_log)\n",
        "        out = logits_items.reshape(logits_items.size(0)*logits_items.size(1), logits_items.size(2))\n",
        "        out_aux = self.model.pred_champ(att_cham)\n",
        "      \n",
        "        gt = gt_items.reshape(gt_items.size(0)*gt_items.size(1), gt_items.size(2))\n",
        "\n",
        "        loss = self.loss(out, gt)\n",
        "        loss_aux = self.loss_aux(out_aux, sel_champions)\n",
        "\n",
        "        prec, num, list_prec = calc_precision_multiclass(out, gt, k=6)\n",
        "        prec1, num, list_prec1 = calc_precision_multiclass(out, gt, k=1)\n",
        "        prec3, num, list_prec3 = calc_precision_multiclass(out, gt, k=3)\n",
        "\n",
        "        recall1, num, list_recall1 = recall_at_k(out, gt, k=1)\n",
        "        recall3, num, list_recall3 = recall_at_k(out, gt, k=3)\n",
        "        recall6, num, list_recall6 = recall_at_k(out, gt, k=6)\n",
        "\n",
        "        f11 = f1_score(recall1, prec1)\n",
        "        f13 = f1_score(recall3, prec3) \n",
        "        f16 = f1_score(recall6, prec)\n",
        "\n",
        "        map6, list_map6 = map_at(out, gt, k=6)\n",
        "        map1, list_map1 = map_at(out, gt, k=1)\n",
        "        map3, list_map3 = map_at(out, gt, k=3)\n",
        "\n",
        "        obj_list = {\n",
        "            'list_prec1': list_prec1,\n",
        "            'list_prec3': list_prec3,\n",
        "            'list_prec': list_prec,\n",
        "            'list_recall1': list_recall1,\n",
        "            'list_recall3': list_recall3,\n",
        "            'list_recall6': list_recall6,\n",
        "            'list_map1': list_map1,\n",
        "            'list_map3': list_map3,\n",
        "            'list_map6': list_map6\n",
        "        }\n",
        "        obj_res = {'val_loss': loss, 'val_loss_aux': loss_aux, 'val_prec': prec, 'num_batch': out.size(0), 'num':num, 'map6': map6, \n",
        "                   'map1': map1, 'map3': map3, 'val_prec1': prec1, 'val_prec3': prec3, 'val_recall1': recall1, \n",
        "                   'val_recall3': recall3, 'val_recall6': recall6, 'val_f1_1': f11, 'val_f1_3': f13, 'val_f1_6': f16, \n",
        "                   'att_weights': att_weights, 'logits_items': logits_items, 'obj_list': obj_list}\n",
        "\n",
        "        #Second Task\n",
        "        if self.aux_task and self.iter_epoch >= self.epoch_to_win:\n",
        "            out_win = y_hat['logits_win']\n",
        "            \n",
        "            gt_win = y['win'].reshape(-1)\n",
        "            _, preds_win = torch.max(out_win, 1)\n",
        "\n",
        "            loss_win = self.second_loss(out_win, gt_win)\n",
        "\n",
        "            acc_win = torch.sum(preds_win == gt_win).item()/out_win.size(0)\n",
        "            obj_res['val_acc'] = acc_win\n",
        "            obj_res['val_loss_win'] = loss_win\n",
        "            obj_res['val_main_loss'] = loss\n",
        "            obj_res['num_batch_acc'] = out_win.size(0)\n",
        "\n",
        "        return obj_res\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_loss = AverageMeter()\n",
        "        avg_loss_aux = AverageMeter()\n",
        "        avg_prec = AverageMeter()\n",
        "        avg_prec1 = AverageMeter()\n",
        "        avg_prec3 = AverageMeter()\n",
        "\n",
        "        avg_recall1 = AverageMeter()\n",
        "        avg_recall3 = AverageMeter()\n",
        "        avg_recall6 = AverageMeter()\n",
        "\n",
        "        avg_f1_1 = AverageMeter()\n",
        "        avg_f1_3 = AverageMeter()\n",
        "        avg_f1_6 = AverageMeter()\n",
        "\n",
        "        avg_map = AverageMeter()\n",
        "        avg_map1 = AverageMeter()\n",
        "        avg_map3 = AverageMeter()\n",
        "\n",
        "        list_att_weights = []\n",
        "        list_logits_items = []\n",
        "\n",
        "        list_prec1 = []\n",
        "        list_prec3 = []\n",
        "        list_prec6 = []\n",
        "\n",
        "        list_recall1 = []\n",
        "        list_recall3 = []\n",
        "        list_recall6 = []\n",
        "\n",
        "        list_map1 = []\n",
        "        list_map3 = []\n",
        "        list_map6 = []\n",
        "\n",
        "        if self.aux_task and self.iter_epoch >= self.epoch_to_win:\n",
        "          avg_main_loss = AverageMeter()\n",
        "          avg_win_loss = AverageMeter()\n",
        "          avg_acc = AverageMeter()\n",
        "\n",
        "        device = None\n",
        "        for x in outputs:\n",
        "\n",
        "          avg_prec.update(x['val_prec'], x['num'])\n",
        "          avg_prec1.update(x['val_prec1'], x['num'])\n",
        "          avg_prec3.update(x['val_prec3'], x['num'])\n",
        "\n",
        "          avg_recall1.update(x['val_recall1'], x['num'])\n",
        "          avg_recall3.update(x['val_recall3'], x['num'])\n",
        "          avg_recall6.update(x['val_recall6'], x['num'])\n",
        "\n",
        "          avg_f1_1.update(x['val_f1_1'], x['num'])\n",
        "          avg_f1_3.update(x['val_f1_3'], x['num'])\n",
        "          avg_f1_6.update(x['val_f1_6'], x['num'])\n",
        "\n",
        "          avg_map.update(x['map6'], x['num_batch'])\n",
        "          avg_map1.update(x['map1'], x['num_batch'])\n",
        "          avg_map3.update(x['map3'], x['num_batch'])\n",
        "\n",
        "          list_att_weights.append(x['att_weights'])\n",
        "          list_logits_items.append(x['logits_items'])\n",
        "\n",
        "          list_prec1.extend(x['obj_list']['list_prec1'])\n",
        "          list_prec3.extend(x['obj_list']['list_prec3'])\n",
        "          list_prec6.extend(x['obj_list']['list_prec'])\n",
        "\n",
        "          list_recall1.extend(x['obj_list']['list_recall1'])\n",
        "          list_recall3.extend(x['obj_list']['list_recall3'])\n",
        "          list_recall6.extend(x['obj_list']['list_recall6'])\n",
        "\n",
        "          list_map1.extend(x['obj_list']['list_map1'])\n",
        "          list_map3.extend(x['obj_list']['list_map3'])\n",
        "          list_map6.extend(x['obj_list']['list_map6'])\n",
        "\n",
        "          device = x['val_loss'].device\n",
        "\n",
        "          if self.aux_task and self.iter_epoch >= self.epoch_to_win:\n",
        "            avg_main_loss.update(x['val_main_loss'], x['num_batch'])\n",
        "            avg_win_loss.update(x['val_loss_win'], x['num_batch_acc'])\n",
        "            avg_acc.update(x['val_acc'], x['num_batch_acc'])\n",
        "\n",
        "            avg_loss.update(self.alpha*x['val_main_loss'], x['num_batch'])\n",
        "            avg_loss.update(self.beta*x['val_loss_win'], x['num_batch_acc'])\n",
        "          else:\n",
        "            avg_loss.update(x['val_loss'], x['num_batch'])\n",
        "            avg_loss_aux.update(x['val_loss_aux'], x['num_batch'])\n",
        "\n",
        "        tensorboard_logs = {'val_loss': torch.tensor([avg_loss.avg], device=device), 'val_prec': torch.tensor([avg_prec.avg], device=device), \n",
        "                            'val_map6': torch.tensor([avg_map.avg], device=device), 'val_map1': torch.tensor([avg_map1.avg], device=device),\n",
        "                            'val_map3': torch.tensor([avg_map3.avg], device=device), 'val_prec1': torch.tensor([avg_prec1.avg], device=device), \n",
        "                            'val_prec3': torch.tensor([avg_prec3.avg], device=device), 'val_recall1': torch.tensor([avg_recall1.avg], device=device),\n",
        "                            'val_recall3': torch.tensor([avg_recall3.avg], device=device), 'val_recall6': torch.tensor([avg_recall6.avg], device=device),\n",
        "                            'val_f1_1': torch.tensor([avg_f1_1.avg], device=device), 'val_f1_3': torch.tensor([avg_f1_3.avg], device=device),\n",
        "                            'val_f1_6': torch.tensor([avg_f1_6.avg], device=device)}\n",
        "\n",
        "        if self.aux_task and self.iter_epoch >= self.epoch_to_win:\n",
        "          tensorboard_logs['val_main_loss'] = torch.tensor([avg_main_loss.avg], device=device)\n",
        "          tensorboard_logs['val_win_loss'] = torch.tensor([avg_win_loss.avg], device=device)\n",
        "          tensorboard_logs['val_win_acc'] = torch.tensor([avg_acc.avg], device=device)\n",
        "          print('| loss_val {:5.6f} | main_loss_val {:5.6f} | win_loss_val {:5.6f} | precision_val {:5.6f} | map6_val {:5.6f} | acc_val {:5.6f}'.format(avg_loss.avg, avg_main_loss.avg, \n",
        "                                                                                                                                                        avg_win_loss.avg, avg_prec.avg, \n",
        "                                                                                                                                                        avg_map.avg, avg_acc.avg))\n",
        "        # else:\n",
        "        #   print('| loss_val {:5.6f} | precision1_val {:5.6f} | precision3_val {:5.6f} | precision6_val {:5.6f} | map1_val {:5.6f} | map3_val {:5.6f} | map6_val {:5.6f} | recall1 {:5.6f} | recall3 {:5.6f} | recall6 {:5.6f} | f1_1 {:5.6f} | f1_3 {:5.6f} | f1_6 {:5.6f}'.format(\n",
        "        #       avg_loss.avg, avg_prec1.avg, avg_prec3.avg, avg_prec.avg, avg_map1.avg, avg_map3.avg, avg_map.avg, avg_recall1.avg, avg_recall3.avg, avg_recall6.avg, avg_f1_1.avg, avg_f1_3.avg, avg_f1_6.avg))\n",
        "        \n",
        "        path_save_att = path_save_att_format.format(str(self.conf['index_split']), str(self.conf['exp']), str(self.iter_epoch))\n",
        "        path_save_list_metrics = path_save_list_metrics_format.format(str(self.conf['index_split']), str(self.conf['exp']), str(self.iter_epoch))\n",
        "        weights_items = {\n",
        "            'list_att_weights': list_att_weights,\n",
        "            'list_logits_items': list_logits_items\n",
        "        }\n",
        "\n",
        "        list_metrics = {\n",
        "            'list_prec1': list_prec1, \n",
        "            'list_prec3': list_prec3,\n",
        "            'list_prec6': list_prec6,\n",
        "            'list_recall1': list_recall1,\n",
        "            'list_recall3': list_recall3,\n",
        "            'list_recall6': list_recall6,\n",
        "            'list_map1': list_map1,\n",
        "            'list_map3': list_map3,\n",
        "            'list_map6': list_map6\n",
        "        }\n",
        "        save_att_weights(weights_items, path_save_att)\n",
        "        save_att_weights(list_metrics, path_save_list_metrics)\n",
        "        return {'avg_val_loss': avg_loss.avg,  'avg_val_prec': avg_prec.avg, 'val_map6': avg_map.avg,'progress_bar': tensorboard_logs,'log': tensorboard_logs}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # OPTIONAL\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        \n",
        "        return self.validation_end(outputs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # REQUIRED\n",
        "        # can return multiple optimizers and learning_rate schedulers\n",
        "        # (LBFGS it is automatically supported, no need for closure function)\n",
        "        if self.optim == 'adabound':\n",
        "          optimizer = adabound.AdaBound(self.model.parameters(), lr=1e-3, final_lr=0.1)\n",
        "        else:\n",
        "          optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        return optimizer\n",
        "    \n",
        "    def train_dataset(self):\n",
        "\n",
        "      data = get_partition(self.index_split, list_trainset)\n",
        "      composed = transforms.Compose([RandomSort_Part(),\n",
        "                               RandomSort_Team()])\n",
        "      train_dataset = LolDataset(data, transform=composed)\n",
        "      return train_dataset\n",
        "\n",
        "    @pl.data_loader\n",
        "    def train_dataloader(self):\n",
        "        \n",
        "        train_dataset = self.train_dataset()\n",
        "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    @pl.data_loader\n",
        "    def val_dataloader(self):\n",
        "        #data = list_testset[self.index_split]\n",
        "        data = get_partition(self.index_split, list_testset)\n",
        "        val_dataset = LolDataset(data)\n",
        "        return DataLoader(val_dataset, batch_size=self.batch_size)\n",
        "    \n",
        "    @pl.data_loader\n",
        "    def test_dataloader(self):\n",
        "        # OPTIONAL\n",
        "        return self.val_dataloader()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyRfaqN8XvYi"
      },
      "source": [
        "# Config file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Aa7VmxeYF7X"
      },
      "source": [
        "This config establish the model hyperparameters like:\n",
        "\n",
        "1. index_split - num of the partition used to train.\n",
        "2. optim - optimizer (could be adam or adabound).\n",
        "3. batch_size - Batch size \n",
        "4. embeddings_size - model dim\n",
        "5. nhead - number of attention heads \n",
        "6. nlayers - number of encoder layers\n",
        "7. exp - experiment number\n",
        "8. epochs - number of epoch\n",
        "9. exp_name - experiment name in comet.ml\n",
        "10. alpha, beta - importance weights for losses\n",
        "11. win_task - enable the auxiliary task.\n",
        "12. learnable_team_emb - when it is True the team embedding is learnable \n",
        "otherwise it is static.  \n",
        "13. teacher_forcing - enable the teacher forcing for the auxiliary task.\n",
        "14. init_epoch - indicate the epoch when the second task start. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqm4Zi0_ha8W"
      },
      "source": [
        "conf = {\n",
        "    'index_split': 0,\n",
        "    'optim': 'adam',\n",
        "    'seed': 1642,\n",
        "    'batch_size': 100,\n",
        "    'embeddings_size': 512,\n",
        "    'nhead': 2,\n",
        "    'nlayers': 1, \n",
        "    'nhid': 2048, \n",
        "    'dropout': 0.5,\n",
        "    'exp': 13,\n",
        "    'epochs': 10,\n",
        "    'exp_name': 'Main_tasks_rec_only_winners_final_prueba',\n",
        "    'win_task': False,\n",
        "    'alpha': 1,\n",
        "    'beta': 1,\n",
        "    'learnable_team_emb': True,\n",
        "    'teacher_forcing': False,\n",
        "    'init_epoch': 2\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVtKoVTcYDS1"
      },
      "source": [
        "# Training and evaluation executor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIBfoXNe1TOh"
      },
      "source": [
        "from pytorch_lightning import Trainer\n",
        "\n",
        "path_save = '/content/gdrive/My Drive/Proyecto_RecSys/split/{}/exp_recsys/{}/checkpoints/'.format(str(conf['index_split']), str(conf['exp']))\n",
        "path_save_att_format = '/content/gdrive/My Drive/Proyecto_RecSys/split/{}/exp_recsys/{}/checkpoints/att_weights_{}.pkl'\n",
        "path_save_list_metrics_format = '/content/gdrive/My Drive/Proyecto_RecSys/split/{}/exp_recsys/{}/checkpoints/list_metrics_{}.pkl'\n",
        "\n",
        "model = LolRecAttModel(conf)\n",
        "\n",
        "checkpoint_callback = get_checkpointer(path_save,'avg_val_prec')\n",
        "\n",
        "\n",
        "comet_logger = CometLogger(\n",
        "    experiment_name=conf['exp_name'],\n",
        "    api_key = 'YOUR_KEY',\n",
        "    project_name=\"YOUR_PROJECT_NAME\",\n",
        "    workspace = 'YOUR_WORKSPACE'\n",
        ")\n",
        "trainer = Trainer(\n",
        "    gpus=[0],\n",
        "    distributed_backend='dp',\n",
        "    logger=comet_logger,\n",
        "    max_epochs=conf['epochs'],\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    show_progress_bar=False,\n",
        "    gradient_clip_val=0.5\n",
        ")\n",
        "\n",
        "trainer.fit(model)   "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}